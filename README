hundo.py - ищи абитуриентов в базе данных admlist.ru
====================================================
простой способ находить поданные заявления друзей в вузы.


Требования
----------
Перед тем, как запустить скрипт, вы должны установить Python (версии 3.6 или
выше) и библиотеки, записанные в requirements.txt:

	python -m pip install -r requirements.txt


Запуск hundo.py
-----------------
Вызовите скрипт с помощью Python, введите фамилию и имя интересующих вас людей,
разделяя абитуриентов переносом строки. Последней строкой передайте нажатие
CTRL+D:
	python hundo.py
	Иванов Иван
	Александров Александр
	<CTRL+D>

Либо используйте Unix input перенаправление для поиска из файла:
	python hundo.py < names.txt

Для большей информации читайте help-сообщение:
	python hundo.py --help


FAQ
---

Я не понимаю, что написано выше, но хочу то же самое. Что мне делать?

	Скачайте Python с сайта www.python.org/downloads, установите файл, откройте
	командную строку или терминал и введите туда строчку из пункта "Требования".
	Далее, изучите данный сайт:
	https://realpython.com/run-python-scripts/#how-to-run-python-scripts-using-the-command-line

Почему скрипт работает так долго?

	Скрипту надо скачать и обработать более 1000 HTML-документов. Скорость
	работы зависит от вашего интернет-соединения, количества поданных заявлений
	и нагрузки на сайт admlist.ru.

Можно ли ускорить работу скрипта?

	Кажется, bottleneck скрипта находится в получении ответа от сервера. Поиск
	имен внутри огромных таблиц совершается с помощью алгоритма Ахо-Корасика,
	написанного на C. Анализ вызовов функций и методов также показывает, что
	большую часть времени занимает получение ответа от сервера. Запросы
	отправляются асинхронно, в разных потоках с целью максимально оптимизировать
	IO. Возможно распараллелить обработку результатов cервера, но эти операции
	на процессоре Intel Core i3 занимают менее процента времени работы, поэтому
	несущественно увеличат производительность.

Скрипт показывает UnicodeDecodeError! Что делать?

	При обработке ответов с сервера чаще всего примерно 0.01% страниц
	неправильно декодируются. Причина не ясна, но, предположительно, сервер сам
	отдает невалидные данные. Можно смириться, можно запустить скрипт еще раз.

У меня есть идея по улучшению кода! Можно ли поучаствовать в разработке?

	Конечно! Исходный код распространяется под лицензией Apache 2. Если у вас
	есть желание и знания, милости просим в Merge Requests или в e-mail с
	патчами. Но, пожалуйста, придерживайтесь PEP8 и оригинального стиля авторов.

